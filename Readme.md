# ü§ñ Syst√®me de Classification de Documents

[![Technical Report](https://img.shields.io/badge/Documentation-Technical%20Report-blue?style=for-the-badge&logo=read-the-dots)](./Technical_Report.pdf)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## üìã Overview
This project involves the ground-up construction of a Large Language Model (LLM), focusing on the core architectural principles of modern generative AI. Beyond simple implementation, this project serves as a research framework to explore **neural architecture design**, **tokenization strategies**, and **model interpretability**.

## üìÑ Academic Documentation
For a deep dive into the mathematical foundations and performance analysis of this implementation, please refer to the full technical report:
> **[Download Technical Report (PDF)](./Technical_Report_LLM.pdf)**

## üìã Table des Mati√®res

1. [Vue d'ensemble](#vue-densemble)
2. [Architecture du syst√®me](#architecture-du-syst√®me)
3. [Technologies utilis√©es](#technologies-utilis√©es)
4. [Installation](#installation)
5. [Configuration](#configuration)
6. [Structure du projet](#structure-du-projet)
7. [Utilisation](#utilisation)
8. [Classes de documents support√©es](#classes-de-documents-support√©es)
9. [Algorithme de fusion](#algorithme-de-fusion)
10. [API et Fonctions principales](#api-et-fonctions-principales)
11. [D√©pannage](#d√©pannage)
12. [Performance et optimisation](#performance-et-optimisation)
13. [Roadmap](#roadmap)

---

## üéØ Vue d'ensemble

Ce projet impl√©mente un **syst√®me de classification hybride de documents** combinant :
- **NLP (Natural Language Processing)** via Gemini AI (90% du poids)
- **Computer Vision** via ResNet50 fine-tun√© (10% du poids)

### Objectif
Classifier automatiquement des documents administratifs marocains/francophones (cartes d'identit√©, factures, relev√©s bancaires, etc.) avec une haute pr√©cision en combinant l'analyse textuelle et visuelle.

### Cas d'usage
- ‚úÖ Automatisation du traitement de documents administratifs
- ‚úÖ Num√©risation et indexation de dossiers clients
- ‚úÖ Syst√®me de gestion documentaire intelligent
- ‚úÖ V√©rification et validation de documents
- ‚úÖ Recherche s√©mantique dans une base documentaire

---

## üèóÔ∏è Architecture du syst√®me

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    DOCUMENT D'ENTR√âE                         ‚îÇ
‚îÇ                  (PDF ou Image JPG/PNG)                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                     ‚îÇ              ‚îÇ                          ‚îÇ
                     ‚ñº              ‚ñº                          ‚ñº
           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
           ‚îÇ  EXTRACTION ‚îÇ  ‚îÇ  EXTRACTION ‚îÇ         ‚îÇ  CONVERSION ‚îÇ
           ‚îÇ    TEXTE    ‚îÇ  ‚îÇ    IMAGE    ‚îÇ         ‚îÇ  PDF ‚Üí IMG  ‚îÇ
           ‚îÇ   (PyMuPDF) ‚îÇ  ‚îÇ    (PIL)    ‚îÇ         ‚îÇ  (PyMuPDF)  ‚îÇ
           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ                ‚îÇ                        ‚îÇ
                  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                        ‚îÇ
                  ‚îÇ  ‚îÇ                                      ‚îÇ
                  ‚ñº  ‚ñº                                      ‚ñº
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ   OCR (optionnel)‚îÇ                      ‚îÇ                 ‚îÇ
         ‚îÇ   Pytesseract    ‚îÇ                      ‚îÇ                 ‚îÇ
         ‚îÇ  fra+ara+eng     ‚îÇ                      ‚îÇ                 ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                      ‚îÇ                 ‚îÇ
                  ‚îÇ                                ‚îÇ                 ‚îÇ
                  ‚ñº                                ‚ñº                 ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îÇ
         ‚îÇ  CLASSIFICATION  ‚îÇ              ‚îÇ  CLASSIFICATION ‚îÇ       ‚îÇ
         ‚îÇ       NLP        ‚îÇ              ‚îÇ       CV        ‚îÇ       ‚îÇ
         ‚îÇ   (Gemini AI)    ‚îÇ              ‚îÇ   (ResNet50)    ‚îÇ       ‚îÇ
         ‚îÇ                  ‚îÇ              ‚îÇ                 ‚îÇ       ‚îÇ
         ‚îÇ  7 classes       ‚îÇ              ‚îÇ  5 classes      ‚îÇ       ‚îÇ
         ‚îÇ  d√©taill√©es      ‚îÇ              ‚îÇ  g√©n√©rales      ‚îÇ       ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ
                  ‚îÇ                                 ‚îÇ                ‚îÇ
                  ‚îÇ   Classe + Confiance            ‚îÇ  Classe + Conf ‚îÇ
                  ‚îÇ                                 ‚îÇ                ‚îÇ
                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                ‚îÇ
                                 ‚îÇ                                   ‚îÇ
                                 ‚ñº                                   ‚îÇ
                        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                          ‚îÇ
                        ‚îÇ  FUSION SCORES  ‚îÇ                          ‚îÇ
                        ‚îÇ                 ‚îÇ                          ‚îÇ
                        ‚îÇ  90% √ó NLP +    ‚îÇ                          ‚îÇ
                        ‚îÇ  10% √ó CV       ‚îÇ                          ‚îÇ
                        ‚îÇ                 ‚îÇ                          ‚îÇ
                        ‚îÇ  + Bonus accord ‚îÇ                          ‚îÇ
                        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                          ‚îÇ
                                 ‚îÇ                                   ‚îÇ
                                 ‚ñº                                   ‚îÇ
                        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                          ‚îÇ
                        ‚îÇ R√âSULTAT FINAL  ‚îÇ                          ‚îÇ
                        ‚îÇ                 ‚îÇ                          ‚îÇ
                        ‚îÇ ‚Ä¢ Classe finale ‚îÇ                          ‚îÇ
                        ‚îÇ ‚Ä¢ Score final   ‚îÇ                          ‚îÇ
                        ‚îÇ ‚Ä¢ Accord NLP/CV ‚îÇ                          ‚îÇ
                        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                          ‚îÇ
                                 ‚îÇ                                   ‚îÇ
                                 ‚ñº                                   ‚îÇ
                        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                          ‚îÇ
                        ‚îÇ   INDEXATION    ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚îÇ                 ‚îÇ
                        ‚îÇ ‚Ä¢ ChromaDB      ‚îÇ
                        ‚îÇ ‚Ä¢ Embeddings    ‚îÇ
                        ‚îÇ ‚Ä¢ M√©tadonn√©es   ‚îÇ
                        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üõ†Ô∏è Technologies utilis√©es

### Frameworks & Libraries

| Technologie | Version | Usage |
|------------|---------|-------|
| **Python** | 3.8+ | Langage principal |
| **Streamlit** | 1.28+ | Interface web |
| **PyTorch** | 2.0+ | Deep Learning (ResNet) |
| **Google Generative AI** | Latest | NLP (Gemini) |
| **ChromaDB** | 0.4+ | Base de donn√©es vectorielle |
| **PyMuPDF (fitz)** | 1.23+ | Extraction PDF |
| **Pytesseract** | 0.3+ | OCR |
| **Pillow (PIL)** | 10.0+ | Traitement d'images |
| **TorchVision** | 0.15+ | Mod√®les CV pr√©-entra√Æn√©s |

### Mod√®les IA

1. **Gemini 2.0 Flash Exp** (NLP)
   - Classification textuelle
   - G√©n√©ration d'embeddings
   - R√©ponses RAG

2. **ResNet50 Fine-tun√©** (CV)
   - Classification d'images
   - 5 classes de documents
   - Poids personnalis√©s (`resnet_finetuned.pth`)

---

## üì¶ Installation

### Pr√©requis

- **Python 3.8+**
- **Tesseract OCR** (pour l'extraction de texte des images scann√©es)
- **Cl√© API Google Gemini**

### √âtape 1 : Cloner le repository

```bash
git clone https://github.com/votre-repo/document-classifier.git
cd document-classifier
```

### √âtape 2 : Cr√©er un environnement virtuel

```bash
# Windows
python -m venv venv
venv\Scripts\activate

# Linux/Mac
python3 -m venv venv
source venv/bin/activate
```

### √âtape 3 : Installer les d√©pendances Python

```bash
pip install -r requirements.txt
```

**Contenu de `requirements.txt` :**
```txt
streamlit>=1.28.0
google-generativeai>=0.3.0
chromadb>=0.4.0
PyPDF2>=3.0.0
PyMuPDF>=1.23.0
pytesseract>=0.3.10
pdf2image>=1.16.3
Pillow>=10.0.0
torch>=2.0.0
torchvision>=0.15.0
python-dotenv>=1.0.0
numpy>=1.24.0
```

### √âtape 4 : Installer Tesseract OCR

#### Windows
1. T√©l√©charger l'installeur : https://github.com/UB-Mannheim/tesseract/wiki
2. Installer dans `C:\Program Files\Tesseract-OCR\`
3. Ajouter au PATH ou configurer dans `.env`

#### Linux (Ubuntu/Debian)
```bash
sudo apt-get update
sudo apt-get install tesseract-ocr
sudo apt-get install tesseract-ocr-fra tesseract-ocr-ara tesseract-ocr-eng
```

#### macOS
```bash
brew install tesseract
brew install tesseract-lang
```

### √âtape 5 : V√©rifier l'installation

```bash
python -c "import torch; print(f'PyTorch: {torch.__version__}')"
python -c "import streamlit; print(f'Streamlit: {streamlit.__version__}')"
tesseract --version
```

---

## ‚öôÔ∏è Configuration

### Fichier `.env`

Cr√©ez un fichier `.env` √† la racine du projet :

```env
# API Key Google Gemini (OBLIGATOIRE)
GEMINI_API_KEY=votre_cle_api_ici

# Chemin Tesseract (Windows uniquement)
TESSERACT_CMD=C:\Program Files\Tesseract-OCR\tesseract.exe

# Nom de la collection ChromaDB (optionnel)
COLLECTION_NAME=documents_hybrid

# Dossier de documents local (optionnel)
DOCUMENTS_FOLDER=./documents
```

### Obtenir une cl√© API Gemini

1. Allez sur https://makersuite.google.com/app/apikey
2. Connectez-vous avec votre compte Google
3. Cliquez sur "Create API Key"
4. Copiez la cl√© dans votre fichier `.env`

### Fichier `gabarits.json`

Ce fichier d√©finit les classes pour le mod√®le ResNet et les seuils de confiance :

```json
{
  "classes": ["id_card", "bank_statement", "elec_and_water_bill", "employer_doc", "other"],
  "thresholds": {
    "cv_confidence": 0.8,
    "nlp_confidence": 0.7,
    "fusion_rejection": 0.5
  },
  "geometry": {
    "id_card": {
      "min_ratio": 1.3,
      "max_ratio": 1.8,
      "requires_face": true
    },
    "others": {
      "min_ratio": 0.5,
      "max_ratio": 1.0,
      "requires_face": false
    }
  },
  "keywords": {
    "id_card": ["CNIE", "Nationale", "Royaume", "Maroc", "N√© le", "Nom", "Pr√©nom"],
    "bank_statement": ["Solde", "Banque", "IBAN", "Virement", "Retrait"],
    "elec_and_water_bill": ["kWh", "Compteur", "Lydec", "ONE", "Facture"],
    "employer_doc": ["Salaire", "Paie", "Attestation", "CNSS"],
    "other": ["Autre", "Document"]
  }
}
```

---

## üìÅ Structure du projet

```
document-classifier/
‚îÇ
‚îú‚îÄ‚îÄ app.py                      # Application Streamlit principale
‚îú‚îÄ‚îÄ gabarits.json              # Configuration des classes ResNet
‚îú‚îÄ‚îÄ resnet_finetuned.pth       # Poids du mod√®le ResNet50
‚îú‚îÄ‚îÄ .env                       # Variables d'environnement
‚îú‚îÄ‚îÄ requirements.txt           # D√©pendances Python
‚îú‚îÄ‚îÄ README.md                  # Cette documentation
‚îÇ
‚îú‚îÄ‚îÄ chroma_db/                 # Base de donn√©es ChromaDB (g√©n√©r√©)
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ
‚îú‚îÄ‚îÄ documents/                 # Dossier de documents √† indexer (optionnel)
‚îÇ   ‚îú‚îÄ‚îÄ cin_001.pdf
‚îÇ   ‚îú‚îÄ‚îÄ facture_eau.jpg
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ
‚îî‚îÄ‚îÄ venv/                      # Environnement virtuel (ignor√© par git)
    ‚îî‚îÄ‚îÄ ...
```

---

## üöÄ Utilisation

### Lancer l'application

```bash
streamlit run app.py
```

L'application s'ouvrira automatiquement dans votre navigateur √† `http://localhost:8501`

### Interface utilisateur

L'application comporte **3 onglets principaux** :

#### üì§ Onglet 1 : Classification

**Upload de documents :**
1. Cliquez sur "Browse files"
2. S√©lectionnez vos documents :
   - **PDFs** : Multi-pages support√©es
   - **Images** : JPG, PNG, JPEG, BMP, TIFF
3. La classification d√©marre **automatiquement**

**R√©sultats affich√©s :**
- **Score NLP** : Classification Gemini + confiance
- **Score CV** : Classification ResNet + confiance
- **Score Final** : Fusion pond√©r√©e (90% NLP + 10% CV)
- **Indicateur d'accord** : ‚úÖ accord ou ‚ö†Ô∏è d√©saccord
- **Texte extrait** (pour les images via OCR)

#### üîç Onglet 2 : Recherche

**Recherche s√©mantique :**
1. Tapez une question en langage naturel
   - Exemple : *"Quelles sont mes factures d'eau de janvier ?"*
2. Filtrez par type de document (optionnel)
3. Ajustez le nombre de r√©sultats (1-10)
4. Cliquez sur "Rechercher"

**R√©sultats :**
- R√©ponse g√©n√©r√©e par Gemini bas√©e sur le contexte
- Sources avec m√©tadonn√©es compl√®tes
- Scores de classification pour chaque source

#### üìä Onglet 3 : Statistiques

**Visualisation de la collection :**
- Nombre total de documents index√©s
- Nombre de types diff√©rents
- Taux d'accord NLP/CV (en %)
- Scores moyens (NLP, CV, Final)
- R√©partition par type de document
- Option de suppression de la collection

---

## üìã Classes de documents support√©es

### Classes NLP (Gemini) - 7 classes d√©taill√©es

| Classe | Description | Mots-cl√©s |
|--------|-------------|-----------|
| **CIN_RECTO** | Carte d'identit√© (recto) | Photo, nom, pr√©nom, date de naissance, lieu de naissance, nationalit√© |
| **CIN_VERSO** | Carte d'identit√© (verso) | Adresse, profession, taille, signature, autorit√© |
| **FACTURE_EAU** | Facture d'eau | LYDEC, RADEEMA, ONEP, m¬≥, index, consommation |
| **FACTURE_ELECTRICITE** | Facture d'√©lectricit√© | ONE, LYDEC, kWh, puissance, tension |
| **RELEVE_BANCAIRE** | Relev√© bancaire | Attijariwafa, BMCE, IBAN, virement, solde |
| **DOCUMENT_EMPLOYEUR** | Attestation de travail | Bulletin de paie, CNSS, salaire, employeur |
| **AUTRE_DOCUMENT** | Autre type | Documents non classifi√©s |

### Classes CV (ResNet50) - 5 classes g√©n√©rales

| Classe | Description | Mapping NLP |
|--------|-------------|-------------|
| **id_card** | Carte d'identit√© | CIN_RECTO, CIN_VERSO |
| **bank_statement** | Relev√© bancaire | RELEVE_BANCAIRE |
| **elec_and_water_bill** | Facture eau/√©lectricit√© | FACTURE_EAU, FACTURE_ELECTRICITE |
| **employer_doc** | Document employeur | DOCUMENT_EMPLOYEUR |
| **other** | Autre document | AUTRE_DOCUMENT |

---

## üßÆ Algorithme de fusion

### Formule de base

```python
Score_Final = (Score_NLP √ó 0.90) + (Score_CV √ó 0.10)
```

### Bonus d'accord

Si les deux mod√®les sont d'accord (m√™me famille de classes) :

```python
Score_Final = (Score_NLP √ó 0.90) + (Score_CV √ó 0.10) + 0.05
```

### Exemple de calcul

**Cas 1 : Accord entre les mod√®les**
```
NLP : CIN_RECTO (confiance 0.95)
CV  : id_card (confiance 0.88)
‚Üí Accord ‚úÖ (CIN_RECTO ‚Üí id_card)

Score_Final = (0.95 √ó 0.90) + (0.88 √ó 0.10) + 0.05
            = 0.855 + 0.088 + 0.05
            = 0.993 (99.3%)

Classe finale : CIN_RECTO
```

**Cas 2 : D√©saccord entre les mod√®les**
```
NLP : FACTURE_EAU (confiance 0.82)
CV  : id_card (confiance 0.65)
‚Üí D√©saccord ‚ö†Ô∏è

Score_Final = (0.82 √ó 0.90) + (0.65 √ó 0.10)
            = 0.738 + 0.065
            = 0.803 (80.3%)

Classe finale : FACTURE_EAU (priorit√© au NLP)
```

### Mapping des classes

```python
CLASS_MAPPING = {
    "id_card": ["CIN_RECTO", "CIN_VERSO"],
    "elec_and_water_bill": ["FACTURE_EAU", "FACTURE_ELECTRICITE"],
    "bank_statement": ["RELEVE_BANCAIRE"],
    "employer_doc": ["DOCUMENT_EMPLOYEUR"],
    "other": ["AUTRE_DOCUMENT"]
}
```

---

## üîß API et Fonctions principales

### 1. Classification NLP

```python
def classify_document_page_nlp(model, page_content: str) -> Tuple[str, float]:
    """
    Classifie une page avec le LLM Gemini
    
    Args:
        model: Instance du mod√®le Gemini
        page_content: Texte √† classifier
    
    Returns:
        (classe_nlp, score_confiance)
        - classe_nlp: Une des 7 classes NLP
        - score_confiance: Float entre 0.0 et 1.0
    """
```

### 2. Classification CV

```python
class ResNetClassifier:
    def predict(self, image: Image.Image) -> Tuple[str, float, Dict]:
        """
        Pr√©dit la classe d'une image avec ResNet50
        
        Args:
            image: Image PIL
        
        Returns:
            (classe_cv, score_confiance, probabilites_toutes_classes)
            - classe_cv: Une des 5 classes CV
            - score_confiance: Float entre 0.0 et 1.0
            - probabilites_toutes_classes: Dict {classe: proba}
        """
```

### 3. Fusion des pr√©dictions

```python
def fuse_predictions(nlp_class: str, nlp_conf: float, 
                     cv_class: str, cv_conf: float,
                     weights: Dict = {"nlp": 0.90, "cv": 0.10}) -> Tuple[str, float, Dict]:
    """
    Fusionne les pr√©dictions NLP et CV avec pond√©ration
    
    Args:
        nlp_class: Classe pr√©dite par NLP
        nlp_conf: Confiance NLP
        cv_class: Classe pr√©dite par CV
        cv_conf: Confiance CV
        weights: Poids de fusion (d√©faut: 90% NLP, 10% CV)
    
    Returns:
        (classe_finale, score_final, details)
    """
```

### 4. Extraction de texte

```python
def extract_text_from_pdf(pdf_path: str, use_ocr: bool = True) -> List[Dict]:
    """
    Extrait le texte page par page d'un PDF
    
    Args:
        pdf_path: Chemin du fichier PDF
        use_ocr: Activer l'OCR pour les pages scann√©es
    
    Returns:
        Liste de dictionnaires avec :
        - page_num: Num√©ro de page
        - content: Texte extrait
        - file_name: Nom du fichier
    """
```

### 5. G√©n√©ration d'embeddings

```python
def generate_embedding(text: str) -> List[float]:
    """
    G√©n√®re un embedding vectoriel avec Gemini
    
    Args:
        text: Texte √† vectoriser
    
    Returns:
        Vecteur d'embedding (768 dimensions)
    """
```

### 6. Recherche s√©mantique

```python
def search_documents(collection, query: str, filters: Dict = None, n_results: int = 5):
    """
    Recherche s√©mantique dans la base ChromaDB
    
    Args:
        collection: Collection ChromaDB
        query: Question en langage naturel
        filters: Filtres optionnels (par type de document)
        n_results: Nombre de r√©sultats √† retourner
    
    Returns:
        R√©sultats de recherche avec documents et m√©tadonn√©es
    """
```

---

## üêõ D√©pannage

### Probl√®me 1 : Erreur de chargement ResNet

**Erreur :**
```
size mismatch for fc.weight: copying a param with shape torch.Size([5, 2048]) 
from checkpoint, the shape in current model is torch.Size([4, 2048])
```

**Solution :**
Le mod√®le a √©t√© entra√Æn√© sur 5 classes mais `gabarits.json` n'en contient que 4.

Ajoutez la classe manquante dans `gabarits.json` :
```json
{
  "classes": ["id_card", "bank_statement", "elec_and_water_bill", "employer_doc", "other"]
}
```

### Probl√®me 2 : OCR ne fonctionne pas

**Erreur :**
```
TesseractNotFoundError: tesseract is not installed or it's not in your PATH
```

**Solution Windows :**
1. T√©l√©chargez Tesseract : https://github.com/UB-Mannheim/tesseract/wiki
2. Installez dans `C:\Program Files\Tesseract-OCR\`
3. Ajoutez dans `.env` :
```env
TESSERACT_CMD=C:\Program Files\Tesseract-OCR\tesseract.exe
```

**Solution Linux :**
```bash
sudo apt-get install tesseract-ocr tesseract-ocr-fra
```

### Probl√®me 3 : Cl√© API Gemini invalide

**Erreur :**
```
google.api_core.exceptions.PermissionDenied: 403 API key not valid
```

**Solution :**
1. V√©rifiez que la cl√© API est correcte dans `.env`
2. Assurez-vous que l'API Gemini est activ√©e : https://makersuite.google.com/
3. V√©rifiez les quotas de votre API

### Probl√®me 4 : ChromaDB ne persiste pas

**Sympt√¥me :** Les documents disparaissent apr√®s red√©marrage

**Solution :**
V√©rifiez que ChromaDB utilise bien `PersistentClient` :
```python
client = chromadb.PersistentClient(path="./chroma_db")
```

Le dossier `chroma_db/` doit √™tre cr√©√© et contenir des fichiers.

### Probl√®me 5 : M√©moire insuffisante

**Erreur :**
```
RuntimeError: CUDA out of memory
```

**Solution :**
1. R√©duire la taille du batch (traiter les documents un par un)
2. Utiliser CPU au lieu de GPU :
```python
self.device = torch.device("cpu")
```
3. Fermer les autres applications

---

## ‚ö° Performance et optimisation

### Temps de traitement moyen

| Op√©ration | Temps (1 page) |
|-----------|----------------|
| Extraction texte PDF | ~0.5s |
| OCR image (si n√©cessaire) | ~2-3s |
| Classification NLP | ~1-2s |
| Classification CV | ~0.3s |
| G√©n√©ration embedding | ~0.5s |
| Indexation ChromaDB | ~0.2s |
| **Total par page** | **~3-7s** |

### Optimisations possibles

1. **Batch processing** : Traiter plusieurs pages en parall√®le
```python
# √Ä impl√©menter
with ThreadPoolExecutor(max_workers=4) as executor:
    results = executor.map(process_page, pages)
```

2. **Cache des embeddings** : √âviter de recalculer les m√™mes textes
```python
@st.cache_data
def generate_embedding(text: str):
    # ...
```

3. **GPU pour ResNet** : Acc√©l√©ration avec CUDA
```python
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
```

4. **Compression des images** : R√©duire la taille avant classification
```python
image.thumbnail((800, 800))
```

### Limites actuelles

- **Taille max PDF** : ~50 pages (au-del√†, traitement lent)
- **Taille max image** : 10 MB
- **Quota API Gemini** : 60 requ√™tes/minute (gratuit)
- **ChromaDB** : ~100K documents recommand√©

---

## üó∫Ô∏è Roadmap

### Version 1.1 (√Ä venir)
- [ ] Support de formats Word (.docx)
- [ ] Export des r√©sultats en CSV/JSON
- [ ] Traitement batch de dossiers entiers
- [ ] Interface de correction manuelle

### Version 1.2
- [ ] API REST pour int√©gration externe
- [ ] Authentification utilisateurs
- [ ] Multi-langue (anglais, arabe complet)
- [ ] Dashboard analytics avanc√©

### Version 2.0
- [ ] Fine-tuning du mod√®le ResNet sur vos donn√©es
- [ ] Extraction automatique de champs (nom, montant, date)
- [ ] Workflow de validation documentaire
- [ ] Int√©gration OCR cloud (Google Vision, AWS Textract)

---

## üìß Support et Contribution

### Rapporter un bug

Cr√©ez une issue sur GitHub avec :
1. Description du probl√®me
2. √âtapes de reproduction
3. Logs d'erreur
4. Version de Python et d√©pendances

### Contribuer

1. Fork le projet
2. Cr√©ez une branche feature (`git checkout -b feature/AmazingFeature`)
3. Commit vos changements (`git commit -m 'Add AmazingFeature'`)
4. Push vers la branche (`git push origin feature/AmazingFeature`)
5. Ouvrez une Pull Request

---

## üìÑ Licence

Ce projet est sous licence MIT. Voir le fichier `LICENSE` pour plus de d√©tails.

---

## üë• Auteurs

- **Votre Nom** - *D√©veloppement initial* - [VotreGitHub](https://github.com/votre-username)

---

## üôè Remerciements

- Google Gemini pour l'API NLP
- PyTorch pour le framework Deep Learning
- Streamlit pour l'interface utilisateur
- Anthropic Claude pour l'assistance au d√©veloppement

---

## üìä Statistiques du projet

- **Lignes de code** : ~1200
- **Fonctions** : 25+
- **Classes** : 1 (ResNetClassifier)
- **Formats support√©s** : PDF, JPG, PNG, JPEG, BMP, TIFF
- **Langues OCR** : Fran√ßais, Arabe, Anglais

---

**Derni√®re mise √† jour** : Janvier 2025  
**Version** : 1.0.0
